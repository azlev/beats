description: Pipeline for parsing PostgreSQL logs.
processors:
- set:
    field: event.ingested
    value: '{{_ingest.timestamp}}'

- csv:
    field: message
    separator: ","
    target_fields: ["postgresql.log.timestamp",
                    "user.name",
                    "postgresql.log.database",
                    "process.pid",
                    "temp.connection_from",
                    "postgresql.csv.session_id",
                    "temp.session_line_num",
                    "postgresql.csv.command_tag",
                    "temp.session_start_time",
                    "postgresql.csv.virtual_transaction_id",
                    "postgresql.csv.transaction_id",
                    "postgresql.csv.error_severity",
                    "postgresql.csv.sql_state_code",
                    "temp.message",
                    "postgresql.csv.detail",
                    "postgresql.csv.hint",
                    "postgresql.internal_query",
                    "temp.internal_query_pos",
                    "postgresql.csv.context",
                    "postgresql.log.query",
                    "temp.query_pos",
                    "postgresql.csv.location",
                    "postgresql.csv.application_name",
                    "postgresql.csv.backend_type"]
    ignore_missing: true
    trim: true
- remove:
   field: message
   ignore_missing: false

- date:
    field: postgresql.log.timestamp
    target_field: '@timestamp'
    formats:
    - yyyy-MM-dd HH:mm:ss.SSS zz
    - yyyy-MM-dd HH:mm:ss zz

- grok:
   field: temp.connection_from
   ignore_missing: true
   patterns:
    - '^%{DATA:postgresql.csv.client_addr}(:%{NUMBER:postgresql.csv.client_port:int})?$'

- convert:
    field: "postgresql.csv.session_line_num"
    type: long
    ignore_missing: true
- date:
    field: temp.session_start_time
    target_field: postgresql.csv.session_start_time
    formats:
    - yyyy-MM-dd HH:mm:ss.SSS zz
    - yyyy-MM-dd HH:mm:ss zz

- convert:
    field: postgresql.csv.transaction_id
    type: long
    ignore_missing: true
- grok:
    field: temp.message
    ignore_missing: true
    patterns:
    - '^duration: %{NUMBER:temp.duration:float} ms$'
    - '^duration: %{NUMBER:temp.duration:float} ms  %{POSTGRESQL_QUERY_STEP} %{DATA:postgresql.log.query_name}: %{GREEDYDATA:postgresql.csv.message}$'
    - '^duration: %{NUMBER:temp.duration:float} ms  %{POSTGRESQL_QUERY_STEP}: %{GREEDYDATA:postgresql.csv.message}$'
    - '^(%{POSTGRESQL_QUERY_STEP}: )?%{GREEDYDATA:postgresql.csv.message}$'
    pattern_definitions:
      GREEDYDATA: |-
        (.|
        |   )*
      POSTGRESQL_QUERY_STEP: '(parse|bind|statement|fastpath function call|execute|execute fetch from)'
- script:
    lang: painless
    source: ctx.event.duration = Math.round(ctx.temp.duration * params.scale)
    params:
      scale: 1000000
    if: ctx.temp?.duration != null

- remove:
    field: temp
    ignore_missing: true

- set:
    field: event.kind
    value: event
- append:
    field: event.category
    value:
      - database
- append:
    field: related.user
    value: "{{user.name}}"
    if: "ctx?.user?.name != null"

on_failure:
- set:
    field: error.message
    value: '{{ _ingest.on_failure_message }}'
